# The version of the docker-compose standard being followed here
version: '3.4'

# Services are groups of containers handling one aspect of the application
services:
  database: # PostgreSQL
    # Use the PostgreSQL image we made ourselves by running ./scripts/build/postgres.sh
    image: omniport-postgres:latest

    # No matter what, if the container stops, start it again
    restart: always

    # Check the health of the container periodically
    healthcheck:
      test: ['CMD', 'checkhealth']
      retries: 4

      interval: 16m
      timeout: 16s
      start_period: 2m

    # Expose the port 5432 used by PostgreSQL to other containers
    expose:
    - "5432"

    # Run the container as the non-root user
    user: postgres

    # Set the environment variables
    env_file:
    - postgres/database.env

    # Mount the volumes on the database container
    volumes:
      # Mount 'database' as the place where PostgreSQL stores all its data
    - type: volume
      source: database
      target: /var/lib/postgresql/data
      read_only: false

    # Connect to the custom default network
    networks:
    - network

  channel-layer: # Redis
    # Use the Redis image we made ourselves by running ./scripts/build/redis.sh
    image: omniport-redis:latest

    # Check the health of the container periodically
    healthcheck:
      test: ['CMD', 'checkhealth']
      retries: 4

      interval: 16m
      timeout: 16s
      start_period: 2m

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 6379 used by Redis to other containers
    expose:
    - "6379"

    # Run the container as the non-root user
    user: redis

    # Mount the volumes on the channel layer container
    volumes:
      # Mount 'channel_layer' as the place where Redis stores its dumps
    - type: volume
      source: channel_layer
      target: /data
      read_only: false

    # Connect to the custom default network
    networks:
    - network

  session-store: # Redis
    # Use the Redis image we made ourselves by running ./scripts/build/redis.sh
    image: omniport-redis:latest

    # Check the health of the container periodically
    healthcheck:
      test: ['CMD', 'checkhealth']
      retries: 4

      interval: 16m
      timeout: 16s
      start_period: 2m

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 6379 used by Redis to other containers
    expose:
    - "6379"

    # Run the container as the non-root user
    user: redis

    # Mount the volumes on the session store container
    volumes:
      # Mount 'session_store' as the place where Redis stores all its dumps
    - type: volume
      source: session_store
      target: /data
      read_only: false

    # Connect to the custom default network
    networks:
    - network

  communication-store: # Redis
    # Use the Redis image we made ourselves by running ./scripts/build/redis.sh
    image: omniport-redis:latest

    # Check the health of the container periodically
    healthcheck:
      test: ['CMD', 'checkhealth']
      retries: 4

      interval: 16m
      timeout: 16s
      start_period: 2m

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 6379 used by Redis to other containers
    expose:
    - "6379"

    # Run the container as the non-root user
    user: redis

    # Mount the volumes on the communication store container
    volumes:
      # Mount 'communication_store' as the place where Redis stores its dumps
    - type: volume
      source: communication_store
      target: /data
      read_only: false

    # Connect to the custom default network
    networks:
    - network

  redis-gui: # Redis Commander
    # Use the Redis Commander image as is
    image: rediscommander/redis-commander:latest

    # Check the health of the container periodically
    healthcheck:
      test: ['CMD', 'nc', '-z', '127.0.0.1', '8081']
      retries: 4

      interval: 16m
      timeout: 16s
      start_period: 2m

    # No matter what, if the container stops, start it again
    restart: always 
    
    # Expose the port 8081 used by Redis commander to the host
    ports:
    - "8081:8081"

    # Set the REDIS_HOSTS environment variable so that the Redis servers can be connected
    environment:
    - 'REDIS_HOSTS=
      channel-layer:channel-layer,
      session-store:session-store,
      communication-store:communication-store'

    # The services that need to be ready before this one
    depends_on:
    - channel-layer
    - session-store
    - communication-store

    # Connect to the custom default network
    networks:
    - network

  cache: # Memcached
    # Use the Memcached image we made ourselves by running ./scripts/build/memcached.sh
    image: omniport-memcached:latest

    # Check the health of the container periodically
    healthcheck:
      test: ['CMD', 'netcat', '-z', '127.0.0.1', '11211']
      retries: 4

      interval: 16m
      timeout: 16s
      start_period: 2m

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 5672 used by RabbitMQ to other containers
    expose:
    - "11211"

    # Run the container as the non-root user
    user: memcache

    # Connect to the custom default network
    networks:
    - network

  message-broker: # RabbitMQ
    # Use the RabbitMQ image we made ourselves by running ./scripts/build/rabbitmq.sh
    image: omniport-rabbitmq:latest

    # Check the health of the container periodically
    healthcheck:
      test: ['CMD', 'checkhealth']
      retries: 4

      interval: 16m
      timeout: 16s
      start_period: 2m

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 5672 used by RabbitMQ to other containers
    expose:
    - "5672"

    # Expose the ports 15672 to the host at 5672 and 15672
    ports:
    - "15672:15672"

    # Run the container as the non-root user
    user: rabbitmq
    
    # Set the environment variables
    env_file:
    - rabbitmq/message_broker.env

    # Mount the volumes on the message broker container
    volumes:
      # Mount 'rabbitmq-data' as the place where RabbitMQ stores its data
    - type: volume
      source: rabbitmq_data
      target: /var/lib/rabbitmq
      read_only: false

    # Connect to the custom default network
    networks:
    - network

  intranet-server: # Django = Gunicorn + Daphne
    # Use the Django image we made ourselves by running ./scripts/build/django.sh
    image: omniport-django:latest

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the ports 8000 and 8001 used by Gunicorn and Daphne to other containers
    expose:
    - "8000"
    - "8001"

    # Run the container as the non-root user
    user: django

    # Set the SITE_ID environment variable so that the right YAML is processed
    environment:
    - SITE_ID=1
    - NAME=intranet-server

    command: ["supervisord", "-c", "/supervisord.conf"]

    # Mount the volumes on the Django container
    volumes:
      # Mount the code from the 'omniport' folder in the root of the container 
    - type: bind
      source: ./codebase/omniport-backend/omniport
      target: /omniport
      read_only: true

      # Mount the YAML files from the 'configuration' folder in the root of the container
    - type: bind
      source: ./codebase/omniport-backend/configuration
      target: /configuration
      read_only: true

      # Mount the imagery from the 'branding' folder in the root of the container
    - type: bind
      source: ./codebase/omniport-backend/branding
      target: /branding
      read_only: true

      # Mount the third-party service certificates from the 'certificates' folder in the root of the container
    - type: bind
      source: ./codebase/omniport-backend/certificates
      target: /certificates
      read_only: true

      # Mount 'static_files' as its namesake in the root of the container
    - type: volume
      source: static_files
      target: /static_files
      read_only: false
      
      # Mount 'media_files' as its namesake in the root of the container
    - type: volume
      source: media_files
      target: /media_files
      read_only: false

      # Mount 'personal_files' as its namesake in the root of the container
    - type: volume
      source: personal_files
      target: /personal_files
      read_only: false

      # Mount 'supervisor.d' as its namesake in the root of the container
    - type: volume
      source: supervisor.d
      target: /supervisor.d
      read_only: false

      # Mount 'web_server_logs' as its namesake in the root of the container
    - type: volume
      source: web_server_logs
      target: /web_server_logs
      read_only: false

      # mount '.history' as its namesake in the root of the container
    - type: volume
      source: .history
      target: /.history
      read_only: false

    # The services that need to be ready before this one
    depends_on:
    - database
    - channel-layer
    - session-store
    - communication-store
    - message-broker

    # Connect to the custom default network
    networks:
    - network

  internet-server: # Django = Gunicorn + Daphne
    # Use the Django image we made ourselves by running ./scripts/build/django.sh
    image: omniport-django:latest

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the ports 8000 and 8001 used by Gunicorn and Daphne to other containers
    expose:
    - "8000"
    - "8001"

    # Run the container as the non-root user
    user: django

    # Set the SITE_ID environment variable so that the right YAML is processed
    environment:
    - SITE_ID=2
    - NAME=internet-server

    command: ["supervisord", "-c", "/supervisord.conf"]

    # Mount the volumes on the Django container
    volumes:
      # Mount the code from the 'omniport' folder in the root of the container 
    - type: bind
      source: ./codebase/omniport-backend/omniport
      target: /omniport
      read_only: true

      # Mount the YAML files from the 'configuration' folder in the root of the container
    - type: bind
      source: ./codebase/omniport-backend/configuration
      target: /configuration
      read_only: true

      # Mount the imagery from the 'branding' folder in the root of the container
    - type: bind
      source: ./codebase/omniport-backend/branding
      target: /branding
      read_only: true

      # Mount the third-party service certificates from the 'certificates' folder in the root of the container
    - type: bind
      source: ./codebase/omniport-backend/certificates
      target: /certificates
      read_only: true

      # Mount 'static_files' as its namesake in the root of the container
    - type: volume
      source: static_files
      target: /static_files
      read_only: false
      
      # Mount 'media_files' as its namesake in the root of the container
    - type: volume
      source: media_files
      target: /media_files
      read_only: false

      # Mount 'personal_files' as its namesake in the root of the container
    - type: volume
      source: personal_files
      target: /personal_files
      read_only: false

      # Mount 'supervisor.d' as its namesake in the root of the container
    - type: volume
      source: supervisor.d
      target: /supervisor.d
      read_only: false

      # Mount 'web_server_logs' as its namesake in the root of the container
    - type: volume
      source: web_server_logs
      target: /web_server_logs
      read_only: false

      # Mount '.history' as its namesake in the root of the container
    - type: volume
      source: .history
      target: /.history
      read_only: false

    # The services that need to be ready before this one
    depends_on:
    - database
    - channel-layer
    - session-store
    - communication-store
    - message-broker

    # Connect to the custom default network
    networks:
    - network

  reverse-proxy: # NGINX
    # Use the NGINX image we made ourselves by running ./scripts/build/nginx.sh
    image: omniport-nginx:latest

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 80 and 443 used by NGINX to other containers
    expose:
    - "80"
    - "443"

    # Expose the ports 80 and 443 used by NGINX to the host
    ports:
    - "80:80"
    - "443:443"

    # Connect to the custom default network
    networks:
    - network

    # Mount the volumes on the NGINX container
    volumes:
      # Mount the imagery from the 'branding' folder in the root of the container
    - type: bind
      source: ./codebase/omniport-backend/branding
      target: /branding
      read_only: true

      # Mount 'build' as 'frontend' in the root of the container
    - type: bind
      source: ./codebase/omniport-frontend/omniport/build
      target: /frontend
      read_only: true

      # Mount 'cert' as 'cert' in the root of the container
    - type: bind
      source: ./cert
      target: /cert
      read_only: true

      # Mount 'static_files' as its namesake in the root of the container
    - type: volume
      source: static_files
      target: /static_files
      read_only: true

      # Mount 'media_files' as its namesake in the root of the container
    - type: volume
      source: media_files
      target: /media_files
      read_only: true

      # Mount 'personal_files' as its namesake in the root of the container
    - type: volume
      source: personal_files
      target: /personal_files
      read_only: true

      # Mount 'reverse_proxy_logs' as its namesake in the root of the container
    - type: volume
      source: reverse_proxy_logs
      target: /reverse_proxy_logs
      read_only: false

    # The services that need to be ready before this one
    depends_on:
    - intranet-server
    - internet-server

    # Connect to the custom default network
    networks:
    - network

# Volumes are virtual drives connected to containers
volumes:
  # This volume contains the database and PostgreSQL configuration files
  database:
  # This volume contains periodic dumps of the database for backup
  database_backup:

  # This volume contains reverse proxy logs
  reverse_proxy_logs:
  # This volume contains web server logs
  web_server_logs:

  # This volume contains the static files
  static_files:

  # This volume contains the media files
  media_files:
  # This volume contains periodic dumps of the media files for backup
  media_files_backup:

  # This volume contains the personal media files
  personal_files:
  # This volume contains periodic dumps of the personal files for backup
  personal_files_backup:

  # This volume contains the supervisor.d conf files
  supervisor.d:

  # This volume contains the history files
  .history:

  # RabbitMQ needs a volume at /var/lib/rabbitmq/
  rabbitmq_data:

  # Periodic dumps taken by Redis acting as channel layer
  channel_layer:
  # Periodic dumps taken by Redis acting as session store
  session_store:
  # Periodic dumps taken by Redis acting as communication store
  communication_store:

# Networks specify how containers communicate with each other and the host
networks:
  # Create a network to override Docker's ambiguously named default
  network:
